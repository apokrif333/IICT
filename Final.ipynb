{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import functools\n",
    "import operator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/lenta-ru-news.csv')\n",
    "\n",
    "clear_df = pd.DataFrame({})\n",
    "clear_df['text'] = df.text.str.lower().str.replace(r\"(\\n|\\t|\\xa0)\", ' ').str.replace(r\"\\.\\s+\", r\".\").str.replace(\n",
    "    r\"(«|»|,|:|\\(|\\)|\\[|\\]|,)\", \"\")\n",
    "\n",
    "clear_df['text'] = clear_df['text'].str.split(\".\")\n",
    "clear_df.dropna(inplace=True)\n",
    "all_sentences = functools.reduce(operator.iconcat, clear_df['text'], [])\n",
    "true_idx = [idx for idx, sent in enumerate(all_sentences) if sent is not '']\n",
    "all_sentences = list(operator.itemgetter(*true_idx)(all_sentences))\n",
    "\n",
    "need_words = [\"прокурор\", \"следствие\", \"авария\", \"гражданин\", \"указ\", \"акция\", \"белка\", \"граф\", \"орган\", \"вид\"]\n",
    "need_sentences = []\n",
    "for idx in tqdm(range(len(all_sentences))):\n",
    "    if len(set(need_words) & set(all_sentences[idx].split())) != 0:\n",
    "        need_sentences.append(all_sentences[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 13_000\n",
    "step = 500\n",
    "\n",
    "for sent_idx in range(start, len(need_sentences), step):\n",
    "    print(sent_idx)\n",
    "    \n",
    "    elmo_tf = hub.Module(\"http://files.deeppavlov.ai/deeppavlov_data/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz\", trainable=True)\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    sent_batch = need_sentences[sent_idx-step:sent_idx]\n",
    "    vectors = sess.run(elmo_tf(sent_batch, signature=\"default\", as_dict=True)[\"word_emb\"])\n",
    "    print(vectors.shape)\n",
    "\n",
    "    for sentence in sent_batch:\n",
    "        new_keys = set(sentence.split()) - set(words_dict.keys())\n",
    "        words_dict.update(\n",
    "            dict(zip(new_keys, len(new_keys) * [[]]))\n",
    "        )\n",
    "\n",
    "    for cur_sentence, cur_vector in tqdm(zip(sent_batch, vectors)):\n",
    "        split_sentence = cur_sentence.split()\n",
    "        for word in range(len(split_sentence)):\n",
    "            words_dict[split_sentence[word]].append(cur_vector[word])\n",
    "\n",
    "    for word in need_words:\n",
    "        difference = []\n",
    "        for i in range(len(words_dict[word])-1):\n",
    "            difference.append(np.linalg.norm(words_dict[word][i] - words_dict[word][i+1]))\n",
    "\n",
    "        print(word, np.std(difference))\n",
    "        \n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
